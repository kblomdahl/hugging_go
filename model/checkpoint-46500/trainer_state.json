{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9826812059012187,
  "eval_steps": 500,
  "global_step": 46500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 0.3787808418273926,
      "learning_rate": 4.9466538379302975e-05,
      "loss": 2.5767,
      "step": 500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3964139521121979,
      "learning_rate": 4.893200769724182e-05,
      "loss": 1.7066,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4957476258277893,
      "learning_rate": 4.8397477015180676e-05,
      "loss": 1.6178,
      "step": 1500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6614033579826355,
      "learning_rate": 4.786294633311952e-05,
      "loss": 1.5673,
      "step": 2000
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7085061073303223,
      "learning_rate": 4.732841565105837e-05,
      "loss": 1.5153,
      "step": 2500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7246727347373962,
      "learning_rate": 4.6793884968997224e-05,
      "loss": 1.4638,
      "step": 3000
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.972885251045227,
      "learning_rate": 4.625935428693608e-05,
      "loss": 1.4212,
      "step": 3500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9631979465484619,
      "learning_rate": 4.5724823604874924e-05,
      "loss": 1.387,
      "step": 4000
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.033876657485962,
      "learning_rate": 4.519029292281377e-05,
      "loss": 1.3616,
      "step": 4500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0103741884231567,
      "learning_rate": 4.465576224075262e-05,
      "loss": 1.342,
      "step": 5000
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0618726015090942,
      "learning_rate": 4.412123155869147e-05,
      "loss": 1.3232,
      "step": 5500
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1963952779769897,
      "learning_rate": 4.358670087663032e-05,
      "loss": 1.3074,
      "step": 6000
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2588140964508057,
      "learning_rate": 4.305217019456917e-05,
      "loss": 1.3018,
      "step": 6500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0986194610595703,
      "learning_rate": 4.251763951250802e-05,
      "loss": 1.2873,
      "step": 7000
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1963504552841187,
      "learning_rate": 4.198310883044687e-05,
      "loss": 1.2769,
      "step": 7500
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.150275707244873,
      "learning_rate": 4.144857814838572e-05,
      "loss": 1.2669,
      "step": 8000
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3357118368148804,
      "learning_rate": 4.091404746632457e-05,
      "loss": 1.2635,
      "step": 8500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3277013301849365,
      "learning_rate": 4.0379516784263414e-05,
      "loss": 1.2494,
      "step": 9000
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2406846284866333,
      "learning_rate": 3.984498610220227e-05,
      "loss": 1.2471,
      "step": 9500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2990951538085938,
      "learning_rate": 3.931045542014112e-05,
      "loss": 1.2402,
      "step": 10000
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.302466630935669,
      "learning_rate": 3.877592473807997e-05,
      "loss": 1.234,
      "step": 10500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2457255125045776,
      "learning_rate": 3.824139405601882e-05,
      "loss": 1.227,
      "step": 11000
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1932480335235596,
      "learning_rate": 3.770686337395767e-05,
      "loss": 1.2223,
      "step": 11500
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3390485048294067,
      "learning_rate": 3.7172332691896516e-05,
      "loss": 1.2162,
      "step": 12000
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3909074068069458,
      "learning_rate": 3.663887107119949e-05,
      "loss": 1.2143,
      "step": 12500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.313240647315979,
      "learning_rate": 3.6104340389138336e-05,
      "loss": 1.2108,
      "step": 13000
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.360457181930542,
      "learning_rate": 3.556980970707719e-05,
      "loss": 1.2088,
      "step": 13500
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3144210577011108,
      "learning_rate": 3.5035279025016036e-05,
      "loss": 1.2036,
      "step": 14000
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3306339979171753,
      "learning_rate": 3.450181740431901e-05,
      "loss": 1.1998,
      "step": 14500
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3380430936813354,
      "learning_rate": 3.3967286722257856e-05,
      "loss": 1.1965,
      "step": 15000
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4057718515396118,
      "learning_rate": 3.343275604019671e-05,
      "loss": 1.1902,
      "step": 15500
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2904428243637085,
      "learning_rate": 3.289929441949968e-05,
      "loss": 1.1847,
      "step": 16000
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.314795732498169,
      "learning_rate": 3.236476373743853e-05,
      "loss": 1.186,
      "step": 16500
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.3697011470794678,
      "learning_rate": 3.183023305537738e-05,
      "loss": 1.1822,
      "step": 17000
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2825727462768555,
      "learning_rate": 3.129570237331623e-05,
      "loss": 1.1773,
      "step": 17500
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.2584038972854614,
      "learning_rate": 3.076117169125508e-05,
      "loss": 1.1809,
      "step": 18000
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.341880440711975,
      "learning_rate": 3.0226641009193928e-05,
      "loss": 1.1756,
      "step": 18500
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4519509077072144,
      "learning_rate": 2.9692110327132778e-05,
      "loss": 1.1725,
      "step": 19000
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.2758657932281494,
      "learning_rate": 2.9157579645071632e-05,
      "loss": 1.1726,
      "step": 19500
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.4162099361419678,
      "learning_rate": 2.86241180243746e-05,
      "loss": 1.1697,
      "step": 20000
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4556465148925781,
      "learning_rate": 2.8089587342313452e-05,
      "loss": 1.1627,
      "step": 20500
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3453859090805054,
      "learning_rate": 2.75550566602523e-05,
      "loss": 1.163,
      "step": 21000
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.5012280941009521,
      "learning_rate": 2.7020525978191146e-05,
      "loss": 1.1631,
      "step": 21500
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4178929328918457,
      "learning_rate": 2.6487064357494122e-05,
      "loss": 1.1579,
      "step": 22000
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.4326752424240112,
      "learning_rate": 2.5952533675432972e-05,
      "loss": 1.1588,
      "step": 22500
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.3352409601211548,
      "learning_rate": 2.541800299337182e-05,
      "loss": 1.1545,
      "step": 23000
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.3082810640335083,
      "learning_rate": 2.488347231131067e-05,
      "loss": 1.1547,
      "step": 23500
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3888055086135864,
      "learning_rate": 2.4350010690613643e-05,
      "loss": 1.1531,
      "step": 24000
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4371328353881836,
      "learning_rate": 2.3815480008552493e-05,
      "loss": 1.1512,
      "step": 24500
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4635593891143799,
      "learning_rate": 2.328094932649134e-05,
      "loss": 1.1514,
      "step": 25000
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.4063234329223633,
      "learning_rate": 2.2746418644430194e-05,
      "loss": 1.1538,
      "step": 25500
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.383034110069275,
      "learning_rate": 2.2212957023733163e-05,
      "loss": 1.1494,
      "step": 26000
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.3964160680770874,
      "learning_rate": 2.1678426341672013e-05,
      "loss": 1.1448,
      "step": 26500
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.4789278507232666,
      "learning_rate": 2.1143895659610864e-05,
      "loss": 1.1463,
      "step": 27000
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.5180612802505493,
      "learning_rate": 2.060936497754971e-05,
      "loss": 1.1474,
      "step": 27500
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3896360397338867,
      "learning_rate": 2.0075903356852684e-05,
      "loss": 1.1431,
      "step": 28000
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.4037069082260132,
      "learning_rate": 1.9541372674791534e-05,
      "loss": 1.1404,
      "step": 28500
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.4393681287765503,
      "learning_rate": 1.9006841992730384e-05,
      "loss": 1.1409,
      "step": 29000
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.5119450092315674,
      "learning_rate": 1.847231131066923e-05,
      "loss": 1.1393,
      "step": 29500
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.459693431854248,
      "learning_rate": 1.7938849689972208e-05,
      "loss": 1.1364,
      "step": 30000
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.5112384557724,
      "learning_rate": 1.7404319007911055e-05,
      "loss": 1.1371,
      "step": 30500
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.4464422464370728,
      "learning_rate": 1.6869788325849905e-05,
      "loss": 1.1346,
      "step": 31000
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.5184195041656494,
      "learning_rate": 1.6336326705152878e-05,
      "loss": 1.1333,
      "step": 31500
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.428878664970398,
      "learning_rate": 1.5801796023091725e-05,
      "loss": 1.1363,
      "step": 32000
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.4728472232818604,
      "learning_rate": 1.5267265341030575e-05,
      "loss": 1.1303,
      "step": 32500
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.5075486898422241,
      "learning_rate": 1.4732734658969424e-05,
      "loss": 1.1287,
      "step": 33000
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.4314815998077393,
      "learning_rate": 1.4198203976908276e-05,
      "loss": 1.1272,
      "step": 33500
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.4177170991897583,
      "learning_rate": 1.3663673294847123e-05,
      "loss": 1.1295,
      "step": 34000
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.6449638605117798,
      "learning_rate": 1.3129142612785975e-05,
      "loss": 1.1323,
      "step": 34500
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.4059244394302368,
      "learning_rate": 1.2594611930724825e-05,
      "loss": 1.1284,
      "step": 35000
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.5431194305419922,
      "learning_rate": 1.2061150310027796e-05,
      "loss": 1.1227,
      "step": 35500
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.462396264076233,
      "learning_rate": 1.1526619627966647e-05,
      "loss": 1.1264,
      "step": 36000
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.4991600513458252,
      "learning_rate": 1.0992088945905495e-05,
      "loss": 1.1197,
      "step": 36500
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.4818955659866333,
      "learning_rate": 1.0457558263844346e-05,
      "loss": 1.1229,
      "step": 37000
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.3323649168014526,
      "learning_rate": 9.924096643147317e-06,
      "loss": 1.1231,
      "step": 37500
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.5820890665054321,
      "learning_rate": 9.389565961086166e-06,
      "loss": 1.1246,
      "step": 38000
    },
    {
      "epoch": 2.47,
      "grad_norm": 1.5370676517486572,
      "learning_rate": 8.855035279025016e-06,
      "loss": 1.1231,
      "step": 38500
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.5039589405059814,
      "learning_rate": 8.320504596963866e-06,
      "loss": 1.1213,
      "step": 39000
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.59144926071167,
      "learning_rate": 7.787042976266838e-06,
      "loss": 1.1221,
      "step": 39500
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.3972588777542114,
      "learning_rate": 7.252512294205688e-06,
      "loss": 1.121,
      "step": 40000
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.4539968967437744,
      "learning_rate": 6.717981612144537e-06,
      "loss": 1.117,
      "step": 40500
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.4686205387115479,
      "learning_rate": 6.183450930083387e-06,
      "loss": 1.119,
      "step": 41000
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.4178900718688965,
      "learning_rate": 5.649989309386359e-06,
      "loss": 1.1175,
      "step": 41500
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.4372813701629639,
      "learning_rate": 5.1154586273252085e-06,
      "loss": 1.1198,
      "step": 42000
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.5114504098892212,
      "learning_rate": 4.580927945264058e-06,
      "loss": 1.1142,
      "step": 42500
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.3809603452682495,
      "learning_rate": 4.0463972632029074e-06,
      "loss": 1.1185,
      "step": 43000
    },
    {
      "epoch": 2.79,
      "grad_norm": 1.475542426109314,
      "learning_rate": 3.5129356425058805e-06,
      "loss": 1.1178,
      "step": 43500
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.4523670673370361,
      "learning_rate": 2.9784049604447295e-06,
      "loss": 1.1147,
      "step": 44000
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.4325178861618042,
      "learning_rate": 2.4438742783835794e-06,
      "loss": 1.1156,
      "step": 44500
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.3755866289138794,
      "learning_rate": 1.909343596322429e-06,
      "loss": 1.1143,
      "step": 45000
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.3902156352996826,
      "learning_rate": 1.375881975625401e-06,
      "loss": 1.1108,
      "step": 45500
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.4257086515426636,
      "learning_rate": 8.413512935642506e-07,
      "loss": 1.1148,
      "step": 46000
    },
    {
      "epoch": 2.98,
      "grad_norm": 1.3588943481445312,
      "learning_rate": 3.068206115031003e-07,
      "loss": 1.1121,
      "step": 46500
    }
  ],
  "logging_steps": 500,
  "max_steps": 46770,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 9.846589133212877e+16,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
